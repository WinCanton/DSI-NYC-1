{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Lab\n",
    "\n",
    "In this lab we will compare the performance of all the models we have learned about so far, using the car evaluation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "The [car evaluation dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/car/) is in the assets/datasets folder. By now you should be very familiar with this dataset.\n",
    "\n",
    "1. Load the data into a pandas dataframe\n",
    "- Encode the categorical features properly: define a map that preserves the scale (assigning smaller numbers to words indicating smaller quantities)\n",
    "- Separate features from target into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../assets/datasets/car.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'high' 'med' 'low']\n",
      "['vhigh' 'high' 'med' 'low']\n",
      "['small' 'med' 'big']\n",
      "['low' 'med' 'high']\n",
      "['unacc' 'acc' 'vgood' 'good']\n",
      "['2' '4' 'more']\n",
      "['2' '3' '4' '5more']\n"
     ]
    }
   ],
   "source": [
    "print df.buying.unique()\n",
    "print df.maint.unique()\n",
    "print df.lug_boot.unique()\n",
    "print df.safety.unique()\n",
    "print df.acceptability.unique()\n",
    "print df.persons.unique()\n",
    "print df.doors.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map1 = {'low':1,\n",
    "        'med':2,\n",
    "        'high':3,\n",
    "        'vhigh':4}\n",
    "map2 = {'small':1,\n",
    "        'med':2,\n",
    "        'big':3}\n",
    "map3 = {'unacc':1,\n",
    "        'acc':2,\n",
    "        'good':3,\n",
    "        'vgood':4}\n",
    "map4 = {'2': 2,\n",
    "        '4': 4,\n",
    "        'more': 5}\n",
    "map5 = {'2': 2,\n",
    "        '3': 3,\n",
    "        '4': 4,\n",
    "        '5more': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety\n",
       "0       4      4      2        2         1       1\n",
       "1       4      4      2        2         1       2\n",
       "2       4      4      2        2         1       3\n",
       "3       4      4      2        2         2       1\n",
       "4       4      4      2        2         2       2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [c for c in df.columns if c != 'acceptability']\n",
    "dfn = df.copy()\n",
    "\n",
    "dfn.buying= df.buying.map(map1)\n",
    "dfn.maint= df.maint.map(map1)\n",
    "dfn.lug_boot = df.lug_boot.map(map2)\n",
    "dfn.persons = df.persons.map(map4)\n",
    "dfn.doors = df.doors.map(map5)\n",
    "dfn.safety = df.safety.map(map1)\n",
    "dfn.acceptability = df.acceptability.map(map3)\n",
    "\n",
    "X = dfn[features]\n",
    "y = dfn['acceptability']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying           1728 non-null int64\n",
      "maint            1728 non-null int64\n",
      "doors            1728 non-null int64\n",
      "persons          1728 non-null int64\n",
      "lug_boot         1728 non-null int64\n",
      "safety           1728 non-null int64\n",
      "acceptability    1728 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 94.6 KB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful preparation\n",
    "\n",
    "Since we will compare several models, let's write a couple of helper functions.\n",
    "\n",
    "1. Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "    - make sure that the data is shuffled and stratified\n",
    "2. Define a function called `evaluate_model`, that trains the model on the train set, tests it on the test, calculates:\n",
    "    - accuracy score\n",
    "    - confusion matrix\n",
    "    - classification report\n",
    "3. Initialize a global dictionary to store the various models for later retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print cm\n",
    "    print cr\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a KNN\n",
    "\n",
    "Let's start with `KNeighborsClassifier`.\n",
    "\n",
    "1. Initialize a KNN model\n",
    "- Evaluate it's performance with the function you previously defined\n",
    "- Find the optimal value of K using grid search\n",
    "    - Be careful on how you perform the cross validation in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354   9   0   0]\n",
      " [  8 107   0   0]\n",
      " [  0   9  11   1]\n",
      " [  0   2   0  18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98       363\n",
      "          2       0.84      0.93      0.88       115\n",
      "          3       1.00      0.52      0.69        21\n",
      "          4       0.95      0.90      0.92        20\n",
      "\n",
      "avg / total       0.95      0.94      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "a = evaluate_model(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {'n_neighbors': range(2,60)}\n",
    "\n",
    "gsknn = GridSearchCV(KNeighborsClassifier(),\n",
    "                     params, n_jobs=-1,\n",
    "                     cv=KFold(len(y), n_folds=3, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=1728, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95428240740740744"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354   9   0   0]\n",
      " [  8 107   0   0]\n",
      " [  0   9  11   1]\n",
      " [  0   2   0  18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98       363\n",
      "          2       0.84      0.93      0.88       115\n",
      "          3       1.00      0.52      0.69        21\n",
      "          4       0.95      0.90      0.92        20\n",
      "\n",
      "avg / total       0.95      0.94      0.94       519\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94412331406551064"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(gsknn.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_models['knn'] = {'model': gsknn.best_estimator_,\n",
    "                     'score': a}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Bagging + KNN\n",
    "\n",
    "Now that we have found the optimal K, let's wrap `KNeighborsClassifier` in a BaggingClassifier and see if the score improves.\n",
    "\n",
    "1. Wrap the KNN model in a Bagging Classifier\n",
    "- Evaluate performance\n",
    "- Do a grid search only on the bagging classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baggingknn = BaggingClassifier(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[359   4   0   0]\n",
      " [  7 107   1   0]\n",
      " [  0   7  12   2]\n",
      " [  0   4   0  16]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.99      0.98       363\n",
      "          2       0.88      0.93      0.90       115\n",
      "          3       0.92      0.57      0.71        21\n",
      "          4       0.89      0.80      0.84        20\n",
      "\n",
      "avg / total       0.95      0.95      0.95       519\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95183044315992293"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(baggingknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagging_params = {'n_estimators': [10, 20],\n",
    "                  'max_samples': [0.7, 1.0],\n",
    "                  'max_features': [0.7, 1.0],\n",
    "                  'bootstrap_features': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsbaggingknn = GridSearchCV(baggingknn,\n",
    "                            bagging_params, n_jobs=-1,\n",
    "                            cv=KFold(len(y), n_folds=3, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=1728, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [10, 20], 'max_samples': [0.7, 1.0], 'bootstrap_features': [True, False], 'max_features': [0.7, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 0.7,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbaggingknn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[356   7   0   0]\n",
      " [  9 105   1   0]\n",
      " [  0   9  11   1]\n",
      " [  0   5   0  15]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98       363\n",
      "          2       0.83      0.91      0.87       115\n",
      "          3       0.92      0.52      0.67        21\n",
      "          4       0.94      0.75      0.83        20\n",
      "\n",
      "avg / total       0.94      0.94      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_models['gsbaggingknn'] = {'model': gsbaggingknn.best_estimator_,\n",
    "                              'score': evaluate_model(gsbaggingknn.best_estimator_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "Let's see if logistic regression performs better\n",
    "\n",
    "1. Initialize LR and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  11   4   1]\n",
      " [ 59  53   3   0]\n",
      " [  5  15   1   0]\n",
      " [  0  19   0   1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.84      0.96      0.90       363\n",
      "          2       0.54      0.46      0.50       115\n",
      "          3       0.12      0.05      0.07        21\n",
      "          4       0.50      0.05      0.09        20\n",
      "\n",
      "avg / total       0.73      0.77      0.74       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "all_models['lr'] = {'model': lr,\n",
    "                    'score': evaluate_model(lr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 10.0}\n",
      "0.827546296296\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "\n",
    "gslr = GridSearchCV(lr,\n",
    "                    params, n_jobs=-1,\n",
    "                    cv=KFold(len(y), n_folds=3, shuffle=True))\n",
    "\n",
    "gslr.fit(X, y)\n",
    "\n",
    "print gslr.best_params_\n",
    "print gslr.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Trees\n",
    "\n",
    "Let's see if Decision Trees perform better\n",
    "\n",
    "1. Initialize DT and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machines\n",
    "\n",
    "Let's see if SVM perform better\n",
    "\n",
    "1. Initialize SVM and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better\n",
    "\n",
    "1. Initialize RF and ET and test on Train/Test set\n",
    "- Find optimal params with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "Let's compare the scores of the various models.\n",
    "\n",
    "1. Do a bar chart of the scores of the best models. Who's the winner on the train/test split?\n",
    "- Re-test all the models using a 3 fold stratified shuffled cross validation\n",
    "- Do a bar chart with errorbars of the cross validation average scores. is the winner the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "We have encoded the data using a map that preserves the scale.\n",
    "Would our results have changed if we had encoded the categorical data using `pd.get_dummies` or `OneHotEncoder`  to encode them as binary variables instead?\n",
    "\n",
    "1. Repeat the analysis for this scenario. Is it better?\n",
    "- Experiment with other models or other parameters, can you beat your classmates best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
