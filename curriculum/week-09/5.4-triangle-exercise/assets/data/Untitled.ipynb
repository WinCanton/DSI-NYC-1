{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Prediction(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.originalDataFileName = 'cleanData.csv'\n",
    "\n",
    "    def setOriginalDataFileName(self, newName):\n",
    "        self.originalDataFileName = newName\n",
    "\n",
    "    def getOriginalDataFileName(self):\n",
    "        return self.originalDataFileName\n",
    "\n",
    "    def prepareTestData(self, fileName):\n",
    "        #Prepare test data\n",
    "        prep = Data_Preparation()\n",
    "        columnNames = prep.getColumns()\n",
    "        test_data = pd.read_csv(\n",
    "            fileName,\n",
    "            names = columnNames,\n",
    "            sep = r\"\\s*,\\s*\",\n",
    "            na_values = \"?\",\n",
    "            engine = \"python\",\n",
    "        )\n",
    "\n",
    "        #Fill in missing values\n",
    "        #print test_data.count()\n",
    "        test_data['Workclass'].fillna(value = 'Private', inplace=True)\n",
    "        test_data['Occupation'].fillna(value= 'Prof-specialty', inplace=True)\n",
    "        test_data['Country'].fillna(value = 'United-States', inplace = True)\n",
    "        #print test_data.count()\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __selectRelevantFeatures(self, df):\n",
    "        #Select relevant features\n",
    "        relevantFeatures = ['Martial_Status', 'Occupation','Relationship', 'Race', 'Sex',\n",
    "            'Age', 'Education_Num','Capital_Gain', 'Capital_Loss', 'Hours_Per_Week']\n",
    "\n",
    "        #Construct X and y and turn them in numpy arrays\n",
    "        X = df[relevantFeatures].values\n",
    "        y = df['Income'].values\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformTestData(self, train_data, test_data):\n",
    "        #Select the right features for both training and testing data\n",
    "        X_train, y_train = self.__selectRelevantFeatures(train_data)\n",
    "        X_test, y_test = self.__selectRelevantFeatures(test_data)\n",
    "\n",
    "        #Transform categorical variables into integer labels\n",
    "        martial_le = LabelEncoder()\n",
    "        occupation_le = LabelEncoder()\n",
    "        relationship_le = LabelEncoder()\n",
    "        race_le = LabelEncoder()\n",
    "        sex_le = LabelEncoder()\n",
    "        transformers = [martial_le, occupation_le, relationship_le, race_le, sex_le]\n",
    "\n",
    "        for i in range(len(transformers)):\n",
    "            X_train[:,i] = transformers[i].fit_transform(X_train[:,i])\n",
    "            X_test[:,i] = transformers[i].transform(X_test[:,i])\n",
    "\n",
    "        #Dummy code categorical variables\n",
    "        dummy_code = OneHotEncoder(categorical_features = range(5))\n",
    "        X_train = dummy_code.fit_transform(X_train).toarray()\n",
    "        X_test = dummy_code.transform(X_test).toarray()\n",
    "\n",
    "        #Normalize all features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        #Encode y\n",
    "        class_le = LabelEncoder()\n",
    "        y_train = class_le.fit_transform(y_train)\n",
    "        y_test = class_le.transform(y_test)\n",
    "        #print class_le.transform([\"<=50K\", \">50K\"])\n",
    "\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictWithLR(self, test_data, saveModel = False):\n",
    "        #Get data\n",
    "        train_data = pd.read_csv(self.originalDataFileName)\n",
    "        test_data = test_data\n",
    "        X_train, X_test, y_train, y_test = self.transformTestData(train_data, test_data)\n",
    "\n",
    "        #Retrain the model using full original dataset\n",
    "        finalLogisticRegression = LogisticRegression (C =0.01)\n",
    "        finalLogisticRegression.fit(X_train, y_train)\n",
    "\n",
    "        if saveModel == True:\n",
    "            joblib.dump(finalLogisticRegression, \"Final_Logistic_Regression.pkl\", compress=1)\n",
    "\n",
    "        #Make Predictions\n",
    "        predictions = finalLogisticRegression.predict(X_test)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictWithRF(self, test_data, saveModel = False):\n",
    "    #Get data\n",
    "    train_data = pd.read_csv(self.originalDataFileName)\n",
    "    test_data = test_data\n",
    "    X_train, X_test, y_train, y_test = self.transformTestData(train_data, test_data)\n",
    "\n",
    "    #Retrain the model using full original dataset\n",
    "    finalRandomForest = RandomForestClassifier (\n",
    "    min_samples_leaf= 3,\n",
    "    n_estimators = 21,\n",
    "    max_features= 12,\n",
    "    min_samples_split= 4,\n",
    "    max_depth= 67,\n",
    "    random_state = 101\n",
    "    )\n",
    "    finalRandomForest.fit(X_train, y_train)\n",
    "    if saveModel == True:\n",
    "        joblib.dump(finalRandomForest, \"Final_Random_Forest.pkl\", compress=1)\n",
    "    #Make predictions\n",
    "    predictions = finalRandomForest.predict(X_test)\n",
    "    return predictions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-98739bfc835b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
